{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a8406ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from pydataset import data\n",
    "from datetime import date\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from env import get_db_url, user, password, host\n",
    "import acquire\n",
    "import prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f15cc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Given confusion matrix:\n",
    "# What is a false positive? Predicting a cat when it is actually a dog\n",
    "# What is a false negative? Predicting a dog and it was actually a cat\n",
    "Accuracy= (46 + 13) / (46 + 13 + 7 + 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2880dc7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4b51eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "Recall = 46 / (46 + 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dc8b9c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7796610169491526"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2ca4852",
   "metadata": {},
   "outputs": [],
   "source": [
    "Precision = 46 / (46 + 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c2ff1fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8679245283018868"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fef13879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model, if the + is dog, has a high precision outcome, fairly high recall, and moderate accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "409ba9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. C3 Rubber-duck manufacturing\n",
    "# Importing the .csv\n",
    "c3 = pd.read_csv('c3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3875d247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        actual     model1     model2     model3\n",
       "0    No Defect  No Defect     Defect  No Defect\n",
       "1    No Defect  No Defect     Defect     Defect\n",
       "2    No Defect  No Defect     Defect  No Defect\n",
       "3    No Defect     Defect     Defect     Defect\n",
       "4    No Defect  No Defect     Defect  No Defect\n",
       "..         ...        ...        ...        ...\n",
       "195  No Defect  No Defect     Defect     Defect\n",
       "196     Defect     Defect  No Defect  No Defect\n",
       "197  No Defect  No Defect  No Defect  No Defect\n",
       "198  No Defect  No Defect     Defect     Defect\n",
       "199  No Defect  No Defect  No Defect     Defect\n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea980cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_cross = pd.crosstab(c3.model1, c3.actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "862e0a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_cross = pd.crosstab(c3.model2, c3.actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58e96b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3_cross = pd.crosstab(c3.model3, c3.actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69c3f4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_acc = (c3.actual == c3.model1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddf1eaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_acc = (c3.actual == c3.model2).mean()\n",
    "m3_acc = (c3.actual == c3.model3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18b33f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.95, 0.56, 0.555)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1_acc, m2_acc, m3_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c3427b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(actual     Defect  No Defect\n",
       " model1                      \n",
       " Defect          8          2\n",
       " No Defect       8        182,\n",
       " actual     Defect  No Defect\n",
       " model2                      \n",
       " Defect          9         81\n",
       " No Defect       7        103,\n",
       " actual     Defect  No Defect\n",
       " model3                      \n",
       " Defect         13         86\n",
       " No Defect       3         98)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precision - assuming our + is defect\n",
    "m1_cross, m2_cross, m3_cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "109334c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = c3[c3.model1 == 'Defect']\n",
    "(subset.model1 == subset.actual).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e5eae1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = c3[c3.model2 == 'Defect']\n",
    "(subset.model2 == subset.actual).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "828b7d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13131313131313133"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = c3[c3.model3 == 'Defect']\n",
    "(subset.model3 == subset.actual).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd731dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recall - assumiong + is defect\n",
    "subset = c3[c3.actual == 'Defect']\n",
    "(subset.model1 == subset.actual).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2501c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5625"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(subset.model2 == subset.actual).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91f480fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8125"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(subset.model3 == subset.actual).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c50e2a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying as many of the ducks that have a defect as possible\n",
    "\n",
    "# M1 is the only model that has a useful accuracy if the concern accounts for lost time/expense of FP. It also has \n",
    "# much better precision performance, which is best for mass production efficiency of ducks. Guaging for \n",
    "# accuracy and precision makes sense here, and should go with M1. \n",
    "\n",
    "# Defects = Trip to Hawaii\n",
    "\n",
    "# Here you would want to use recall to reduce the high cost of FN (missed defective ducks off assembly line)\n",
    "# This would mean that M3 would probably be the best use given the extreme cost of missing defective ducks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b19b4a23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 4. Gives You Paws\n",
    "paws = pd.read_csv('gives_you_paws.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30f8a912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "      <th>model4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual model1 model2 model3 model4\n",
       "0       cat    cat    dog    cat    dog\n",
       "1       dog    dog    cat    cat    dog\n",
       "2       dog    cat    cat    cat    dog\n",
       "3       dog    dog    dog    cat    dog\n",
       "4       cat    cat    cat    dog    dog\n",
       "...     ...    ...    ...    ...    ...\n",
       "4995    dog    dog    dog    dog    dog\n",
       "4996    dog    dog    cat    cat    dog\n",
       "4997    dog    cat    cat    dog    dog\n",
       "4998    cat    cat    cat    cat    dog\n",
       "4999    dog    dog    dog    dog    dog\n",
       "\n",
       "[5000 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11dde485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dog    3254\n",
       "cat    1746\n",
       "Name: actual, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paws.actual.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b89f2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "paws['baseline'] = 'dog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f3fec7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = paws.columns.drop('actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ac5ebcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_acc = []\n",
    "\n",
    "for col in cols:\n",
    "    comparison_acc.append(col + ' accuracy: ' + str((paws.actual == paws[col]).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6055f4c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model1 accuracy: 0.8074',\n",
       " 'model2 accuracy: 0.6304',\n",
       " 'model3 accuracy: 0.5096',\n",
       " 'model4 accuracy: 0.7426',\n",
       " 'baseline accuracy: 0.6508']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e038d486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1 and model4 do beat the baseline in terms of accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4ad5d0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model1 precision is: 0.8900238338440586\n",
      "model2 precision is: 0.8931767337807607\n",
      "model3 precision is: 0.6598883572567783\n",
      "model4 precision is: 0.7312485304490948\n",
      "baseline precision is: 0.6508\n"
     ]
    }
   ],
   "source": [
    "# precision\n",
    "for col in cols:\n",
    "    subset = paws[paws[col] == 'dog']\n",
    "    print(f'{col} precision is: {(subset[col] == subset.actual).mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a9a4d1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model1 recall is: 0.803318992009834\n",
      "model2 recall is: 0.49078057775046097\n",
      "model3 recall is: 0.5086047940995697\n",
      "model4 recall is: 0.9557467732022127\n",
      "baseline recall is: 1.0\n"
     ]
    }
   ],
   "source": [
    "# recall\n",
    "subset = paws[paws.actual == 'dog']\n",
    "for col in cols:\n",
    "    print(f'{col} recall is: {(subset[col] == subset.actual).mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "326786c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b. On dog pic team, what model to use for phaseI and phaseII?\n",
    "# Would want to use recall for phaseI and precision for phaseII. So probably model4 and then model2. This would \n",
    "# have the machine 'catch' as many dogs as possible (without losing some to cat), and then the humans could ensure \n",
    "# that the actual photos uploaded were really dogs\n",
    "\n",
    "# c. On cat pic team, what model to use for phaseI and phaseII?\n",
    "# Would want to use precision for phaseI with model2 to ensure the lowest chance of assigning cats as dogs. For \n",
    "# phaseII would want to use recall to catch as many dogs as possible to ensure they don't get posted as cats, so\n",
    "# model4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b284489d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model1 accuracy: 0.8074\n",
      "model2 accuracy: 0.6304\n",
      "model3 accuracy: 0.5096\n",
      "model4 accuracy: 0.7426\n",
      "baseline accuracy: 0.6508\n"
     ]
    }
   ],
   "source": [
    "for col in cols:\n",
    "    print(f'{col} accuracy: {sklearn.metrics.accuracy_score(paws.actual, paws[col])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f30a17dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model1 precision: 0.8900238338440586\n",
      "model2 precision: 0.8931767337807607\n",
      "model3 precision: 0.6598883572567783\n",
      "model4 precision: 0.7312485304490948\n",
      "baseline precision: 0.6508\n"
     ]
    }
   ],
   "source": [
    "for col in cols:\n",
    "    print(f'{col} precision: {sklearn.metrics.precision_score(paws.actual, paws[col], pos_label=\"dog\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e17bfa35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model1 recall: 0.803318992009834\n",
      "model2 recall: 0.49078057775046097\n",
      "model3 recall: 0.5086047940995697\n",
      "model4 recall: 0.9557467732022127\n",
      "baseline recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "for col in cols:\n",
    "    print(f'{col} recall: {sklearn.metrics.recall_score(paws.actual, paws[col], pos_label=\"dog\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dc11a203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.69      0.82      0.75      1746\n",
      "         dog       0.89      0.80      0.84      3254\n",
      "\n",
      "    accuracy                           0.81      5000\n",
      "   macro avg       0.79      0.81      0.80      5000\n",
      "weighted avg       0.82      0.81      0.81      5000\n",
      "\n",
      "model2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.48      0.89      0.63      1746\n",
      "         dog       0.89      0.49      0.63      3254\n",
      "\n",
      "    accuracy                           0.63      5000\n",
      "   macro avg       0.69      0.69      0.63      5000\n",
      "weighted avg       0.75      0.63      0.63      5000\n",
      "\n",
      "model3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.36      0.51      0.42      1746\n",
      "         dog       0.66      0.51      0.57      3254\n",
      "\n",
      "    accuracy                           0.51      5000\n",
      "   macro avg       0.51      0.51      0.50      5000\n",
      "weighted avg       0.55      0.51      0.52      5000\n",
      "\n",
      "model4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.81      0.35      0.48      1746\n",
      "         dog       0.73      0.96      0.83      3254\n",
      "\n",
      "    accuracy                           0.74      5000\n",
      "   macro avg       0.77      0.65      0.66      5000\n",
      "weighted avg       0.76      0.74      0.71      5000\n",
      "\n",
      "baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.00      0.00      0.00      1746\n",
      "         dog       0.65      1.00      0.79      3254\n",
      "\n",
      "    accuracy                           0.65      5000\n",
      "   macro avg       0.33      0.50      0.39      5000\n",
      "weighted avg       0.42      0.65      0.51      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in cols:\n",
    "    print(col)\n",
    "    print(sklearn.metrics.classification_report(paws.actual, paws[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e9c92a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python397jvsc74a57bd038cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
